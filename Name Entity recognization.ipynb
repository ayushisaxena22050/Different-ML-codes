{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from itertools import groupby\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Gary Winston Lineker was an excellent football player.\n",
    "GARY WINSTON LINEKER was a striker.\n",
    "gary winston lineker was born in England.\n",
    "gARY WiNsTon lInEker is married to Danielle Bux.\n",
    "Gary W. Lineker, Kanny Sansom and Peter Shilton played together.\n",
    "The defenders:\n",
    "    Gary Stevens\n",
    "    02-02-1995\n",
    "    Kenny Sansom\n",
    "    Terry Butcher\n",
    "    1994-02-03\n",
    "The midfields were:\n",
    "    - Bryan Robson;\n",
    "    - Ray Wilkins;\n",
    "    - Chris Waddle.\n",
    "    1994-02-02\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(text):\n",
    "    continuous_chunk = {}\n",
    "    date_reg_exp2 = re.compile(r'(\\d{2}(/|-|\\.)\\w{3}(/|-|\\.)\\d{4})|([a-zA-Z]{3}\\s\\d{2}(,|-|\\.|,)?\\s\\d{4})|(\\d{2}(/|-|\\.)\\d{2}(/|-|\\.)\\d+)')\n",
    "    i = 0\n",
    "    for m in re.finditer(date_reg_exp2,text):\n",
    "        continuous_chunk[i] = (m.group())\n",
    "        i+=1\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Person(text):\n",
    "    chunked = ne_chunk(nltk.pos_tag(word_tokenize(text)))\n",
    "    continuous_chunk = {}\n",
    "    i=0\n",
    "    current_chunk = []\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree and subtree.label() == 'PERSON':\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "#                 continuous_chunk.append(named_entity)\n",
    "                continuous_chunk[i]=named_entity\n",
    "                i+=1\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GPE(text):\n",
    "    chunked = ne_chunk(nltk.pos_tag(word_tokenize(text)))\n",
    "    continuous_chunk ={}\n",
    "    i=0\n",
    "    current_chunk = []\n",
    "    for subtree in chunked:\n",
    "            if type(subtree) == Tree and subtree.label() == 'GPE':\n",
    "                for token, pos in subtree.leaves():\n",
    "                    continuous_chunk[i]=token\n",
    "                    i+=1\n",
    "            elif current_chunk:\n",
    "                named_entity = \" \".join(current_chunk)\n",
    "                if named_entity not in continuous_chunk:\n",
    "                    continuous_chunk.append(named_entity)\n",
    "                    current_chunk = []\n",
    "            else:\n",
    "                continue\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=get_GPE(text)\n",
    "b=get_Person(text)\n",
    "c=get_date(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch={}\n",
    "if bool(a):\n",
    "    fetch['GPE']=a\n",
    "else:\n",
    "    fetch['GPE']='NULL'\n",
    "if bool(b):\n",
    "    fetch['Name']=b\n",
    "else:\n",
    "    fetch['Name']='NULL'\n",
    "if bool(c):\n",
    "    fetch['Date']=c\n",
    "else:\n",
    "    fetch['Date']='NULL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPE': {0: 'England'},\n",
       " 'Name': {0: 'Gary Winston Lineker',\n",
       "  1: 'Danielle Bux',\n",
       "  2: 'Gary W. Lineker',\n",
       "  3: 'Kanny Sansom',\n",
       "  4: 'Peter Shilton',\n",
       "  5: 'Gary Stevens',\n",
       "  6: 'Kenny Sansom Terry',\n",
       "  7: 'Bryan Robson',\n",
       "  8: 'Ray Wilkins',\n",
       "  9: 'Chris Waddle'},\n",
       " 'Date': {0: '02-02-1995', 1: '94-02-03', 2: '94-02-02'}}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
